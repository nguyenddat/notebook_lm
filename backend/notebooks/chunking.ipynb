{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "234f4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import pipeline\n",
    "from docling.chunking import HybridChunker\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db363d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 15:52:43,995 - INFO - detected formats: [<InputFormat.DOCX: 'docx'>]\n",
      "2025-09-26 15:52:43,998 - INFO - Going to convert document batch...\n",
      "2025-09-26 15:52:43,998 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-09-26 15:52:43,999 - INFO - Processing document test.docx\n",
      "2025-09-26 15:52:44,071 - INFO - Finished converting document test.docx in 0.08 sec.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# doc = DocumentConverter().convert(source=\"../artifacts/1/HIVE-COTE 2.0.pdf-3f1825be-ee35-4d60-996a-55bb4a8b9c07.pdf\").document\n",
    "\n",
    "doc = DocumentConverter().convert(source=\"../artifacts/1/test.docx\").document\n",
    "\n",
    "chunker = HybridChunker(\n",
    "    tokenizer=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    max_tokens=800,\n",
    "    overlap_tokens=200\n",
    ")\n",
    "\n",
    "chunks = list(chunker.chunk(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51884841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Optional\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "class Node(BaseModel):\n",
    "    title: str\n",
    "    level: int\n",
    "    children: List[\"Node\"] = []\n",
    "    doc_items: List[Any] = []\n",
    "    embeddings: Optional[Any] = None\n",
    "\n",
    "Node.model_rebuild()\n",
    "\n",
    "tree_root = Node(title=\"Full Text\", level=0)\n",
    "for chunk in chunks:\n",
    "    chunk_headings = chunk.meta.headings or []\n",
    "    parent_node = tree_root\n",
    "\n",
    "    for heading in chunk_headings:\n",
    "        existing_node = next((n for n in parent_node.children if n.title == heading), None)\n",
    "        if not existing_node:\n",
    "            node = Node(title=heading, level=1)\n",
    "            parent_node.children.append(node)\n",
    "            parent_node = node\n",
    "        else:\n",
    "            parent_node = existing_node\n",
    "    \n",
    "    parent_node.doc_items.extend(chunk.meta.doc_items)\n",
    "\n",
    "def embed_tree(node: Node):\n",
    "    if node.doc_items:\n",
    "        full_text = \" \".join(getattr(item, \"content\", getattr(item, \"text\", \"\")) for item in node.doc_items)\n",
    "        if full_text.strip():\n",
    "            node.embeddings = embeddings_model.embed_query(full_text)\n",
    "    for child in node.children:\n",
    "        embed_tree(child)\n",
    "\n",
    "embed_tree(tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e56f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Node(BaseModel):\n",
    "    index: str\n",
    "    text: str\n",
    "    embedding: Any = None\n",
    "    children: List[\"Node\"] = []\n",
    "    meta: Any = None\n",
    "\n",
    "Node.model_rebuild()\n",
    "\n",
    "node_dict = {}\n",
    "for chunk in chunks:\n",
    "    for item in chunk.meta.doc_items:\n",
    "        \n",
    "    self_ref = chunk.meta.doc_items[0].self_ref\n",
    "    text = getattr(chunk, \"text\", \"\")\n",
    "    node_dict[self_ref] = Node(index=self_ref, text=text, meta=chunk.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    self_ref = chunk.meta.doc_items[0].self_ref\n",
    "    parent_ref = chunk.meta.doc_items[1].parent.cref\n",
    "    if parent_ref and parent_ref in node_dict:\n",
    "        parent_node = node_dict[parent_ref]\n",
    "        child_node = node_dict[item.self_ref]\n",
    "        parent_node.children.append(child_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b44b0953",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'#/texts/4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m root_nodes = [\u001b[43mnode_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_ref\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m chunk.meta.doc_items\n\u001b[32m      2\u001b[39m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item.parent \u001b[38;5;129;01mor\u001b[39;00m item.parent.cref \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_dict]\n",
      "\u001b[31mKeyError\u001b[39m: '#/texts/4'"
     ]
    }
   ],
   "source": [
    "\n",
    "root_nodes = [node_dict[item.self_ref] for chunk in chunks for item in chunk.meta.doc_items\n",
    "              if not item.parent or item.parent.cref not in node_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499998f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
